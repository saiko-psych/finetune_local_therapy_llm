# Finetuning eines Large Language Models f√ºr therapeutische Anwendungen

## üìã Projekt√ºbersicht


Dieses Projekt untersucht die Wirksamkeit des Finetunings von Large Language Models (LLMs) f√ºr therapeutische Gespr√§che durch den Vergleich eines Original Gemma-3-4B Modells mit einer selbst trainierten Version auf realen Mental Health Counseling Daten. Dieses Projekt baut auf diesen Projekt auf: [GitHub](https://github.com/MGerschuetz/localTherapy) 

## üéØ Forschungsziel

**Hauptfragestellung:** Kann durch Finetuning die Qualit√§t therapeutischer Antworten eines LLMs signifikant verbessert werden - und das mit einem Modell, das datenschutzkonform lokal auf Consumer-Hardware l√§uft?

**Motivation f√ºr lokale Modelle:**
- **Datenschutz:** Sensible therapeutische Gespr√§che bleiben vollst√§ndig lokal
- **Verf√ºgbarkeit:** Keine Abh√§ngigkeit von Cloud-APIs oder Internetverbindung
- **Kosten:** Keine laufenden API-Kosten nach einmaligem Setup
- **Kontrolle:** Vollst√§ndige Kontrolle √ºber Modellverhalten und Updates
- **Zug√§nglichkeit:** Demokratisierung von KI-Tools f√ºr therapeutische Anwendungen

**Hypothese:** Ein auf therapeutischen Gespr√§chsdaten finegetuntes 4B-Parameter Modell kann lokal auf Standard-Hardware (8-16GB GPU) betrieben werden und dabei h√∂here semantische √Ñhnlichkeit zu echten Therapeutenantworten zeigen als das urspr√ºngliche Basismodell.

## üî¨ Methodologie

### 1. Datengrundlage

**Prim√§rdataset (Finetuning):**
- `entfane/psychotherapy` - Strukturierte therapeutische Gespr√§che mit Metadaten
- Enth√§lt Informationen zu Krankheitsbild und Therapiestadium
- Aufbereitung: Extraktion von Kontext-Response-Paaren mit Metainformationen

**Evaluationsdataset:**
- `Amod/mental_health_counseling_conversations` - 3.512 echte Therapeut-Patient Gespr√§che
- Zwei Testbedingungen:
  - **Gefiltert:** 50-1000 Zeichen (Context), 50-2000 Zeichen (Response)
  - **Ungefiltert:** Zuf√§llige Auswahl aus allen Daten
- Sample-Gr√∂√üe: 6 (Der Rechenaufwand war sonst zu grp√ü, bzw ist es sich zeitlich nicht mehr ausgegangen)

### 2. Technische Implementierung


**Warum Gemma-3-4B statt gr√∂√üerer Modelle?**
- **Hardware-Anforderungen:** L√§uft auf 8GB GPU (RTX 3070/4060 Ti)
- **Inference-Geschwindigkeit:** ~50-100 Tokens/Sekunde auf Consumer-Hardware
- **Speicherbedarf:** ~4GB VRAM quantisiert vs. ~60GB+ f√ºr 70B Modelle
- **Energieeffizienz:** Lokal betreibbar ohne Serverfarm



### 4. Experimentelles Design

**Evaluationsprozess:**
1. **Input:** Patient Context aus Evaluationsdataset
2. **Generation:** 
   - Original Model ‚Üí Response A
   - Finetuned Model ‚Üí Response B
3. **Ground Truth:** Echte Therapeut-Antwort
4. **Vergleich:** Cosine Similarity (TF-IDF basiert)

**Metriken:**
- Original vs Ground Truth
- Finetuned vs Ground Truth  
- Original vs Finetuned

### 5. Robustheit & Reproduzierbarkeit

**Fehlerbehandlung:**
- Checkpoint System (alle 2 Samples (das kann ge√§ndert werden))
- 3 Retry-Versuche bei API-Fehlern
- Automatische Crash Recovery
- Vollst√§ndiges Logging

**Datenintegrit√§t:**
- Deterministische Seeds (42)
- Versionskontrolle aller Parameter
- Reproduzierbare Train/Test Splits

## üìä Evaluationsstrategie

### Quantitative Metriken

**Cosine Similarity Analysis:**
- **Basis:** TF-IDF Vektorisierung
- **Vergleiche:** 3 pro Sample (1200 total)
- **Aggregation:** Mittelwerte, Standardabweichungen



### Software Dependencies
```python
torch>=2.0.0
transformers>=4.35.0
datasets>=2.14.0
peft>=0.6.0
bitsandbytes>=0.41.0
scikit-learn>=1.3.0
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
```


## üîç Wissenschaftlicher Beitrag

### Methodische Innovation
- **Quantitative LLM-Evaluation:** Objektive Messung der Finetuning-Effektivit√§t auf therapeutischen Daten
- **Robuste Experimentgestaltung:** Systematischer Vergleich mit echten Baseline-Antworten
- **Lokale AI-Architektur:** Demonstration datenschutzkonformer KI-Systeme f√ºr sensible Anwendungen
- **Consumer-Hardware Optimierung:** Beweis der Machbarkeit komplexer AI-Tasks auf Standard-PCs

### Praktische Relevanz f√ºr lokale KI-Systeme
- **Datenschutz-Revolution:** Therapeutische KI ohne Cloud-Abh√§ngigkeit
- **Demokratisierung:** KI-Tools zug√§nglich f√ºr jeden mit Standard-Gaming-PC
- **Kosteneffizienz:** Einmalige Anschaffung vs. laufende API-Kosten (GPT-4: ~$0.03/1K Tokens)
- **Verf√ºgbarkeit:** 24/7 Betrieb ohne Internetabh√§ngigkeit oder Service-Ausf√§lle
- **Anpassbarkeit:** Vollst√§ndige Kontrolle √ºber Modellverhalten und ethische Richtlinien

### Gesellschaftlicher Impact
- **Therapeutische Versorgung:** Unterst√ºtzung in unterversorgten Gebieten
- **Kostenreduktion:** Senkung der Barrieren f√ºr mental health support
- **Forschungsf√∂rderung:** Open-Source Ansatz f√ºr weitere wissenschaftliche Entwicklung
- **Ethik-Standard:** Referenzimplementierung f√ºr verantwortliche lokale KI



## üöÄ Ausf√ºhrung

### 1. Environment Setup

-  virtuelles environment in pyhton 3.10 anlegen und ben√∂tigte pakete installieren!

### 2. Finetuning
environment aktiviern und im Terminal dies ausf√ºhren

```bash
start /B python finetune_gemma.py > finetune_gemma.log 2>&1
powershell -Command "Get-Content .\finetune_gemma.log -Wait -Tail 20"
```

### 3. Evaluation
```bash
python model_evaluation.py
```

### 4. Vergleich und Analyse

Dateien und Visualisierungen werden automatisch erstellt! und sind oben im file evaluation_result6samples zu finden!



## üìù Limitationen & lokale Modell-Realit√§ten

### Technische Limitationen
- **Modellgr√∂√üe:** 4B Parameter vs. 175B+ bei GPT-4 (erwartete Qualit√§tsdifferenz)
- **Kontextl√§nge:** 8K Token Limit vs. 128K bei neueren Cloud-Modellen
- **Multimodalit√§t:** Text-only vs. Vision+Audio F√§higkeiten gr√∂√üerer Modelle
- **Training-Daten:** Begrenzte lokale Trainingsdaten (500 Samples) vs. Cloud-Training

### Evaluation-Limitationen  
- **Evaluationsmetrik:** Cosine Similarity erfasst nicht alle Aspekte therapeutischer Qualit√§t
- **Subjektivit√§t:** Keine menschliche Bewertung der generierten Antworten
- **Sprache:** Evaluierung nur auf englischsprachigen Daten
- **Kontext:** Evaluation nur auf Einzelturn-Gespr√§chen

### Warum diese Limitationen akzeptabel sind
- **Privacy-First:** Datenschutz wiegt Qualit√§tsverluste auf
- **Good-Enough:** 80% Qualit√§t bei 100% Privacy oft ausreichend
- **Verbesserbar:** Lokale Modelle entwickeln sich schnell weiter
- **Spezialisierung:** Finetuning kann Domain-spezifische Defizite ausgleichen

## üîÆ Erkenntnisse, Fazit und Ausblick

es zeigte sich bei diesem Test, dass das finetuned Modell mehr √Ñhnlichkeit zu der grount truth zeigte als das originale Modell. Doch habe ich dies vorerst nur mit 6 samples getestet (ich hatte einen run mit 200 samples bei der Evalauation fast durch doch ist sich dies zeitlich nicht mehr ausgegangen -> dort was das finetuned modell aber auch besser, wenn auch nur leicht). Wenn man die Antworten des finetuned Models sich genauer anschaut merkt man aber schnell, dass es √ºbertrainiert wurde beim finetuning, denn viele Antworten folgen genau dem Muster des Trainingsdatensatz vom finetuning oder ergeben keinen Sinn mehr. Dies wird wohl daher stammen, dass das finetuning mit nur 500 samples durchgef√ºhrt wurde (es wurde early stopping angewendet beim finetuning). Beim finetuning sollten mehrere Datens√§tze kombineirt werden und mit einem viel gr√∂√üeren Datensatz sollte dann das finetuning durchgef√ºhrt werden. Die Evaluation l√§dt auf meinem Ger√§t extrem lange, da ich es nicht geschafft habe diese √ºber CUDA laufen zu lassen (grunds√§tzlich w√§re hier eine sample size von mind. 200 samples anzustreben).

Dieses Projekt zeigt nichtdestotrotz, dass durch ein relativ einfaches finetuning eine Ann√§herung der Antorten des Models zu den original responses in echten Konversationen.


---

**Autor:** [David Matischek]  
**Institution:** [Karl Franzens Universit√§t Graz]  
**Datum:** August 2025  
**Kontakt:** [david.matischek@edu.uni-graz.at]
